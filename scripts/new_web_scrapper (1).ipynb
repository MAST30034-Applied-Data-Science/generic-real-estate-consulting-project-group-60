{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b979aa1-187a-46ab-8c70-5b02f8e6c3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Defining of the dataframe\n",
    "# built-in imports\n",
    "import re\n",
    "from json import dump\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# user packages\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "from urllib.request import urlopen\n",
    "import requests\n",
    "df = pd.DataFrame(columns=['postcode'])\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (X11; CrOS x86_64 12871.102.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.141 Safari/537.36\"}\n",
    "table = BeautifulSoup(requests.get('https://www.worldpostalcodes.org/l1/en/au/australia/list/r1/list-of-postcodes-in-victoria',headers = headers).text, \"html.parser\")\n",
    "# Collecting Ddata\n",
    "for row in table.find_all('tr'):    \n",
    "    # Find all data for each column\n",
    "    columns = row.find_all('td')\n",
    "    \n",
    "    if(columns != []):\n",
    "        postcode = columns[0].text.strip()\n",
    "\n",
    "        df = df.append({'postcode':postcode}, ignore_index=True)    \n",
    "postcodes = df['postcode'].tolist()\n",
    "postcodes = [int(x) for x in postcodes if x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9290d7-9163-4329-bff5-64012a5c8e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A very simple and basic web scraping script. Feel free to\n",
    "use this as a source of inspiration, but, make sure to attribute\n",
    "it if you do so.\n",
    "This is by no means production code.\n",
    "\"\"\"\n",
    "# constants\n",
    "BASE_URL = \"https://www.domain.com.au\"\n",
    "N_PAGES = range(1, 31)  # update this to your liking\n",
    "postcode_list = postcodes # All the postcode in the Victoria\n",
    "\n",
    "# begin code\n",
    "url_links = []\n",
    "property_metadata = defaultdict(dict)\n",
    "# generate list of urls to visit\n",
    "for postcode in postcode_list:\n",
    "    postcode_url = BASE_URL + f\"/rent/?excludedeposittaken=1&sort=default-desc&postcode={postcode}&page=\"\n",
    "    for page in N_PAGES:\n",
    "        url = postcode_url + f\"{page}\"\n",
    "        # find the unordered list (ul) elements which are the results, then\n",
    "        # find all href (a) tags that are from the base_url website.\n",
    "        bs_object = BeautifulSoup(requests.get(url,headers = headers).text, \"html.parser\")\n",
    "        if bs_object.find(\"div\", {\"class\": \"css-18vn4hf\"}) is not None:\n",
    "        # if this page reachs the limit, then break\n",
    "            break\n",
    "        else:\n",
    "            if bs_object.find(\"ul\",{\"data-testid\": \"results\"}) is not None:\n",
    "                # if this page contains the property url then record the url\n",
    "                index_links = bs_object \\\n",
    "                    .find(\n",
    "                        \"ul\",\n",
    "                        {\"data-testid\": \"results\"}\n",
    "                    ) \\\n",
    "                    .findAll(\n",
    "                        \"a\",\n",
    "                        href=re.compile(f\"{BASE_URL}/*\") # the `*` denotes wildcard any\n",
    "                    )\n",
    "                for link in index_links:\n",
    "                    # if its a property address, add it to the list\n",
    "                    if 'address' in link['class']:\n",
    "                        url_links.append(link['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf6dfde-e777-401c-ac02-19040967f58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each url, scrape some basic metadata\n",
    "for property_url in url_links[1:]:\n",
    "    bs_object = BeautifulSoup(requests.get(property_url,headers = headers).text, \"html.parser\")\n",
    "\n",
    "    # looks for the header class to get property name\n",
    "    property_metadata[property_url]['name'] = bs_object \\\n",
    "        .find(\"h1\", {\"class\": \"css-164r41r\"}) \\\n",
    "        .text\n",
    "\n",
    "    \n",
    "    # looks for the div containing a summary title for cost\n",
    "    property_metadata[property_url]['cost_text'] = bs_object \\\n",
    "        .find(\"div\", {\"data-testid\": \"listing-details__summary-title\"}) \\\n",
    "        .text\n",
    "    \n",
    "    property_metadata[property_url]['property_type'] = bs_object \\\n",
    "            .find(\"div\", {\"data-testid\": \"listing-summary-property-type\"}) \\\n",
    "            .text\n",
    "    '''\n",
    "    property_metadata[property_url]['agent'] = [\n",
    "        feature.text for feature in bs_object \\\n",
    "            .find(\"div\", {\"data-testid\": \"listing-details__residential-header-agent-copy\"}) \\\n",
    "            .findAll(\"a\")]\n",
    "    '''\n",
    "    for li_tag in bs_object.find_all('ul', {'data-testid':'listing-summary-strip'}):\n",
    "        value=[]\n",
    "        for span_tag in li_tag.find_all('li'):           \n",
    "            value.append(span_tag.find('strong').text)\n",
    "            property_metadata[property_url]['property_feature'] = value\n",
    "    \n",
    "    \n",
    "    # extract coordinates from the hyperlink provided\n",
    "    # i'll let you figure out what this does :P\n",
    "    property_metadata[property_url]['coordinates'] = [\n",
    "        float(coord) for coord in re.findall(\n",
    "            r'destination=([-\\s,\\d\\.]+)', # use regex101.com here if you need to\n",
    "            bs_object \\\n",
    "                .find(\n",
    "                    \"a\",\n",
    "                    {\"target\": \"_blank\", 'rel': \"noopener noreferer\"}\n",
    "                ) \\\n",
    "                .attrs['href']\n",
    "        )[0].split(',')\n",
    "    ]\n",
    "    property_metadata[property_url]['rooms'] = [\n",
    "        re.findall(r'\\d\\s[A-Za-z]+', feature.text) for feature in bs_object \\\n",
    "            .find(\"div\", {\"data-testid\": \"property-features\"}) \\\n",
    "            .findAll(\"span\", {\"data-testid\": \"property-features-text-container\"})\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    property_metadata[property_url]['desc'] = re \\\n",
    "        .sub(r'<br\\/>', '\\n', str(bs_object.find(\"p\"))) \\\n",
    "        .strip('</p>')\n",
    "    \n",
    "\n",
    "# output to example json in data/raw/\n",
    "\n",
    "with open('unfiltered.json', 'w') as f:\n",
    "    dump(property_metadata, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af28738e-2a72-441b-943a-f3a345d70cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_raw = pd.read_json('unfiltered.json')\n",
    "df_raw = df_raw.T\n",
    "df_raw = df_raw.reset_index(drop=True)\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f697cc20-d01e-4db0-9531-2c3361600a04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "10d9cac1-fb37-48bd-999d-0c7e945d68e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
