{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A very simple and basic web scraping script. Feel free to\n",
    "use this as a source of inspiration, but, make sure to attribute\n",
    "it if you do so.\n",
    "\n",
    "This is by no means production code.\n",
    "\"\"\"\n",
    "# built-in imports\n",
    "import re\n",
    "from json import dump\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# user packages\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "\n",
    "# constants\n",
    "BASE_URL = \"https://www.domain.com.au\"\n",
    "N_PAGES = range(1, 51) # update this to your liking\n",
    "\n",
    "# begin code\n",
    "url_links = []\n",
    "property_metadata = defaultdict(dict)\n",
    "\n",
    "# generate list of urls to visit\n",
    "for page in N_PAGES:\n",
    "    url = BASE_URL + f\"/rent/melbourne-region-vic/?sort=price-desc&page={page}\"\n",
    "    bs_object = BeautifulSoup(urlopen(url), \"lxml\")\n",
    "\n",
    "    # find the unordered list (ul) elements which are the results, then\n",
    "    # find all href (a) tags that are from the base_url website.\n",
    "    index_links = bs_object \\\n",
    "        .find(\n",
    "            \"ul\",\n",
    "            {\"data-testid\": \"results\"}\n",
    "        ) \\\n",
    "        .findAll(\n",
    "            \"a\",\n",
    "            href=re.compile(f\"{BASE_URL}/*\") # the `*` denotes wildcard any\n",
    "        )\n",
    "\n",
    "    for link in index_links:\n",
    "        # if its a property address, add it to the list\n",
    "        if 'address' in link['class']:\n",
    "            url_links.append(link['href'])\n",
    "\n",
    "\n",
    "# for each url, scrape some basic metadata\n",
    "for property_url in url_links[1:]:\n",
    "    bs_object = BeautifulSoup(urlopen(property_url), \"lxml\")\n",
    "\n",
    "    # looks for the header class to get property name\n",
    "    property_metadata[property_url]['name'] = bs_object \\\n",
    "        .find(\"h1\", {\"class\": \"css-164r41r\"}) \\\n",
    "        .text\n",
    "\n",
    "    # looks for the div containing a summary title for cost\n",
    "    property_metadata[property_url]['cost_text'] = bs_object \\\n",
    "        .find(\"div\", {\"data-testid\": \"listing-details__summary-title\"}) \\\n",
    "        .text\n",
    "\n",
    "    # extract coordinates from the hyperlink provided\n",
    "    # i'll let you figure out what this does :P\n",
    "    property_metadata[property_url]['coordinates'] = [\n",
    "        float(coord) for coord in re.findall(\n",
    "            r'destination=([-\\s,\\d\\.]+)', # use regex101.com here if you need to\n",
    "            bs_object \\\n",
    "                .find(\n",
    "                    \"a\",\n",
    "                    {\"target\": \"_blank\", 'rel': \"noopener noreferer\"}\n",
    "                ) \\\n",
    "                .attrs['href']\n",
    "        )[0].split(',')\n",
    "    ]\n",
    "\n",
    "    property_metadata[property_url]['rooms'] = [\n",
    "        re.findall(r'\\d\\s[A-Za-z]+', feature.text)[0] for feature in bs_object \\\n",
    "            .find(\"div\", {\"data-testid\": \"property-features\"}) \\\n",
    "            .findAll(\"span\", {\"data-testid\": \"property-features-text-container\"})\n",
    "    ]\n",
    "\n",
    "    property_metadata[property_url]['desc'] = re \\\n",
    "        .sub(r'<br\\/>', '\\n', str(bs_object.find(\"p\"))) \\\n",
    "        .strip('</p>')\n",
    "\n",
    "# output to example json in data/raw/\n",
    "with open('../data/raw/example.json', 'w') as f:\n",
    "    dump(property_metadata, f)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
