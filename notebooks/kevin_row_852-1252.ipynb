{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b8eb03c-884d-4c45-9d16-5df28c3edaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "这一栏是为了拿维州的全部postcodes\n",
    "'''\n",
    "import pandas as pd\n",
    "# Defining of the dataframe\n",
    "# built-in imports\n",
    "import re\n",
    "from json import dump\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# user packages\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "from urllib.request import urlopen\n",
    "import requests\n",
    "df = pd.DataFrame(columns=['postcode'])\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (X11; CrOS x86_64 12871.102.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.141 Safari/537.36\"}\n",
    "table = BeautifulSoup(requests.get('https://www.worldpostalcodes.org/l1/en/au/australia/list/r1/list-of-postcodes-in-victoria',headers = headers).text, \"html.parser\")\n",
    "# Collecting Ddata\n",
    "for row in table.find_all('tr'):    \n",
    "    # Find all data for each column\n",
    "    columns = row.find_all('td')\n",
    "    \n",
    "    if(columns != []):\n",
    "        postcode = columns[0].text.strip()\n",
    "\n",
    "        df = df.append({'postcode':postcode}, ignore_index=True)    \n",
    "postcodes = df['postcode'].tolist()\n",
    "postcodes = [int(x) for x in postcodes if x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60fc2048-7a57-43b9-a6c7-f21738c7715f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "这个东西是所有需要爬取信息的网站\n",
    "'''\n",
    "url_links = pd.read_csv(\"scrapping_url.csv\",names=[\"links\", \"postcode\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9cbb1d5-b1b6-4e75-83f5-0c9042a7f3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_agents =  ['Mozilla/5.0 (Windows NT 6.1; rv:2.0.1) Gecko/20100101 Firefox/4.0.1',\n",
    "                'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-us) AppleWebKit/534.50 (KHTML, like Gecko) Version/5.1 Safari/534.50',\n",
    "                'Opera/9.80 (Windows NT 6.1; U; en) Presto/2.8.131 Version/11.11',\n",
    "               'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36',\n",
    "               'Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.1; WOW64; Trident/4.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; .NET4.0C; InfoPath.3)'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34cd02e6-9d9b-4392-9cfe-2f14a402f952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funtion 更改当前被ban的ip\n",
    "'''\n",
    "网上的ip貌似链接不到我们要爬的网站，所以换ip的这个function暂时搁置\n",
    "'''\n",
    "def changeIP(current_ip):\n",
    "    url = \"https://free-proxy-list.net/\"\n",
    "    headers = {'User-Agent':random.choice(user_agents)} \n",
    "    bs_object = BeautifulSoup(requests.get(url,headers = headers).text, \"html.parser\") \n",
    "    for tr in bs_object.find(\"tbody\").findAll(\"tr\"):\n",
    "        ip_information = tr.findAll(\"td\")\n",
    "        proxy = ip_information[0].text + \":\" + ip_information[1].text\n",
    "        if ip_information[4].text == \"transparent\" and proxy != current_ip:\n",
    "            break\n",
    "    return proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d706f5f5-b20a-4ac7-a6a5-4fef050f002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "这里是正式开始爬取信息的地方，然后3168以前的邮编已经爬过了，可以尝试爬后面的\n",
    "'''\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    " \n",
    "property_metadata = defaultdict(dict)\n",
    "# local_ip = '45.79.208.64:44554'\n",
    "# current_ip = changeIP(local_ip) \n",
    "\n",
    "for i in range(852,1253):\n",
    "    # sleep for 0-1 seconds\n",
    "    time.sleep(random.random())\n",
    "    \n",
    "    headers = {'User-Agent':random.choice(user_agents)}  \n",
    "    \n",
    "   \n",
    "    bs_object = BeautifulSoup(requests.get(url_links.iloc[i][\"links\"],headers = headers).text, \"html.parser\")\n",
    "    \n",
    "    '''\n",
    "    # if 403 happened, changed current ip address \n",
    "    while bs_object.find(\"head\").find(\"title\").text == \"403 Forbidden\":\n",
    "        current_ip = changeIP(current_ip)\n",
    "        bs_object = BeautifulSoup(requests.get(row[\"links\"],headers = headers, proxies={\"http\": current_ip, \"https\": current_ip}).text, \"html.parser\")\n",
    "    '''    \n",
    "        \n",
    "    postcodes = url_links.iloc[i][\"postcode\"]\n",
    "    bs_element = []\n",
    "    if bs_object.find_all('div', {'class':'property odd clearfix'}) is not None: \n",
    "        bs_element.append(bs_object.find_all('div', {'class':'property odd clearfix'}))\n",
    "    \n",
    "    if bs_object.find_all('div', {'class':'property even clearfix'}) is not None:\n",
    "        bs_element.append(bs_object.find_all('div', {'class':'property even clearfix'}))\n",
    "    \n",
    "    if len(bs_element) > 0:    \n",
    "        for bs in bs_element:     \n",
    "            for prop in bs:\n",
    "                # looks for the header class to get property name\n",
    "                name = prop \\\n",
    "                    .find(\"h2\", {\"class\": \"address\"}) \\\n",
    "                    .text\n",
    "                property_metadata[name]['name'] = prop \\\n",
    "                    .find(\"h2\", {\"class\": \"address\"}) \\\n",
    "                    .text\n",
    "                property_metadata[name]['postcode'] = postcodes\n",
    "\n",
    "                cost = []     \n",
    "                for li in prop.find(\"section\", {\"class\": \"grid-100 historical-price\"}).find(\"ul\"):              \n",
    "                    cost_text = li.text\n",
    "                    cost.append(cost_text)\n",
    "                if \" \" in cost:\n",
    "                    cost.remove(\" \")\n",
    "                property_metadata[name]['cost_text'] = cost\n",
    "\n",
    "                if prop.find(\"p\",{\"class\":\"property-meta type\"}) is not None:\n",
    "                    property_metadata[name]['property_type'] = prop.find(\"p\",{\"class\":\"property-meta type\"}).text\n",
    "\n",
    "                if prop.find(\"p\",{\"class\":\"property-meta bed\"}) is not None:\n",
    "                    property_metadata[name]['bed'] = prop.find(\"p\",{\"class\":\"property-meta bed\"}).text\n",
    "\n",
    "                if prop.find(\"p\",{\"class\":\"property-meta bath\"}) is not None:\n",
    "                    property_metadata[name]['bath'] = prop.find(\"p\",{\"class\":\"property-meta bath\"}).text\n",
    "\n",
    "                if prop.find(\"p\",{\"class\":\"property-meta car\"}) is not None:\n",
    "                    property_metadata[name]['car'] = prop.find(\"p\",{\"class\":\"property-meta car\"}).text\n",
    "\n",
    "                property_metadata[name]['latitude'] = prop[\"data-lat\"]  \n",
    "                property_metadata[name]['longitude'] = prop[\"data-lng\"]\n",
    "\n",
    "# output to csv\n",
    "pd.DataFrame(property_metadata).to_csv(\"row_852_1252.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
